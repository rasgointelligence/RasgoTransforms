# Publish all Transforms in this Repo Production and Staging Environments
# Run job each time something is pushed/committed to remote 'main' branch
name: Publish Transforms

on:
  workflow_dispatch:
    inputs:
      environment:
        description: 'Environment that transforms will be published to'
        default: 'all'
        required: true

jobs:
  publish-transforms:
    runs-on: ubuntu-latest
    defaults:
      run:
        shell: bash

    container:
      image: "python:3.7"

    env:
      PYTHONPATH: /__w/RasgoTransforms/RasgoTransforms
      RASGO_COMMUNITY_API_KEY: ${{ secrets.RASGO_COMMUNITY_API_KEY }}
      RASGO_STAGING_COMMUNITY_API_KEY: ${{ secrets.RASGO_STAGING_COMMUNITY_API_KEY }}
      AWS_ACCESS_KEY_ID: ${{ secrets.S3_UPLOAD_ACCESS_KEY }}
      AWS_SECRET_ACCESS_KEY: ${{ secrets.S3_UPLOAD_SECRET_ACCESS_KEY }}

    steps:
      - uses: actions/checkout@v2

      - name: Install Python Requirements
        run: |
          python -m pip install --upgrade pip
          pip install -r python/requirements.txt

      - name: Publish Transforms on Prod
        if: github.event.inputs.environment == 'production' || github.event.inputs.environment == 'all'
        run: python python/publish_transforms.py "$RASGO_COMMUNITY_API_KEY" -d production

      - name: Publish Transforms on Staging
        if: github.event.inputs.environment == 'staging' || github.event.inputs.environment == 'all'
        run: python python/publish_transforms.py "$RASGO_STAGING_COMMUNITY_API_KEY" -d staging

      - name: Publish Transforms to S3
        if: github.event.inputs.environment == 's3' || github.event.inputs.environment == 'all'
        run: python python/publish_transforms_to_s3.py
